# TiDB Hackathon Blog
回望 10 月，TiDB Hackathon 两天及 Telant Plan 在 PingCAP 广州 Office 度过的这几周真的使我印象深刻。
我是电子科技大学研二的一名学生，我和我的 partner 吕小荣本次是以 PingCAP Talent Plan 学员的身份参加 Hackathon，虽然没有得奖，对于第一次参加 Hackathon 比赛的我来说也是收获满满。Talent Plan 的题目是官方确定的，我们在其中选到的是「基于采样的行数估计」，本文主要阐述在这个题目下的一些设计与实现。

我们通过分析，基于采样的行数估计主要可以解决当前列级别独立的等深直方图和 Count-Min Sketch 统计信息在查询优化中的几个问题：
- 无法对如 `abs(a1)` 这样的表达式进行行数估计
- 无法对列相关的查询进行行数估算
- 长时间没有 `Analyze Table` 将导致统计信息过期

我们就这个选题展开的设计思路主要是：
- 使用表的**样本**在 TiDB SQL Engine 的查询优化器中替代现有统计信息进行物理优化
- 由于表数据可能不断变化导致样本过期，使用**动态采样**的方法进行表的样本收集

打个不太严谨（但易于理解）的比方：这个过程类似于先在优化器中做一次小的表的查询，以查询过程各个算子的结果来指导执行计划的生成，整个过程如下图：

<div align=center>
  <img src=./Img/Imp_process.png height=350>
</div>

## 设计与实现
需要实现上面所说的这个功能，其中就涉及到最核心的三个问题：
- 在那里实现？
- 如何实现对表的采样？
- 如何使用表的采样来估算行数？

### 在哪里实现
先不考虑现在正在完善的 Cascade 优化器，我们先回顾一下 TiDB 当前的默认优化器的实现，以确定应该在什么地方触发表的采样及采样的结果应该用在什么地方。
当前 TiDB 的优化器实现主要是 Volcano 模型，在 `planBuilder` 将 AST 转化为逻辑计划树之后，按照优化阶段分为了**逻辑优化**与**物理优化**两个阶段，逻辑优化阶段使用规则进行逻辑计划树的变换，物理优化阶段主要是使用代价模型来选择物理算子。

传统的物理优化主要决定以下三点：
- **单表**：Access Path
- **两表**：Join Approach
- **多表**：Join Order

当前的 TiDB 对 Join Order 的计算是放在逻辑优化阶段实现的，并没有用到统计信息，于是我们聚焦物理优化阶段使用统计信息选择物理算子这个地方。如决定对于一张表在 KV 上的访问应该是 TableScan，IndexScan 或是 IndexLookUpScan，这在 TiDB 中的实现是将 `DataSource` 这样的逻辑算子转化为 `TableReader`, `IndexReader` 或 `IndexLookUpReader`。

具体的，在进入物理优化的时候，优化器会对逻辑优化的结果中每一个逻辑算子（逻辑计划树的节点）自底向上递归的计算通过节点后的统计信息，然后从 Root 节点出发自顶向下递归调用 `findBestTask` 方法来计算将自己变换成为不同物理算子 `Append` 到孩子节点（子树）上的代价，以此选择一个代价最小的物理算子。

那么触发采样和统计信息的使用可以实现在获取统计信息的部分，具体在 `stats.go` 下。

### 如何实现对表的采样
实现对表的采样需要考虑两个问题：
- 什么时候采集？
- 怎么采集？

对于什么时候采集的问题，我们在 TiDB `tidb_vars.go` 中添加了一个系统变量 `tidb_optimizer_dynamic_sampling` 来确定：
- 当前 TiDB 节点是否需要使用表样本来进行查询优化
- 当前的样本收集是否需要阻塞本次查询（由于可以将样本 cache 到内存中，短时间对于一个表的查询可以复用而不用再次采样）
- 表的采样率

这个系统变量有 `0-10` 共 11 个等级，他们与上述条件的对应关系如下：
| 不使用采样 | 采样但不阻塞查询 | 采样并阻塞本次查询 |
|:-:|:-:|:-:|
| 0 | 1-5 | 6-10 |

对于怎么采集的问题，由于 TiDB 是 SQL-over-NoSQL 的架构，要想实现采样这个功能，我们需要将这种在 TiDB 节点上实现的特殊方法推到 TiKV 上实现对应的操作。

好在 TiDB 在 Analyze Table 统计生成等深直方图和 CM-Sketch 也需要对表的数据进行一次采集，更棒的是，为了提高统计信息生成的效率，TiDB 实现了 FastAnalyze 这个功能，这个功能在 KV 上随机的取一些数据返回到 TiDB 上用于生成等深直方图和 CM-Sketch，在表的行数不大于采样行数的 2 倍时，其行为和普通的 Analyze 一样，如果大于 2 倍采样行数，那么会从表的每个 Region 随机抽取一些元组进行返回而不会 Scan 整个 Region，这样大大提高了效率。

于是我们复用了 FastAnalyze 的部分代码在 TiDB 上实现了采样的过程，具体如下图：

<div align=center>
  <img src=./Img/Sampling.png height=350>
</div>

不一样的是，为了方便后续 expression 的计算，我们在 HistColl 中采用 `Chunk` 的结构维护了样本信息。

### 如何使用表的采样来估算行数
从查询优化器的角度上来讲，行数估计实现在进入物理优化后的第一步，也就是在收集统计信息的时候。由于将采集的样本封装到了 HistColl 中，而优化器在物理优化阶段递归的计算逻辑计划树每个节点的统计信息时能够拿到 `*property.StatsInfo`，也就能直接拿到 HistColl 中的样本，通过样本经过逻辑节点的计算逻辑即可计算出通过这个节点后包括行数的统计信息。

<div align=center>
  <img src=./Img/DeriveStats.png height=300>
</div>

由于采集的时候将样本维护成了 chunk，因此当前在 Selectivity 中的 expression 计算实现只用简单的调用 `expression.VectorizedFilter` 然后对结果的 bool slice 进行统计就能计算出选择率，通过选择率即可计算出行数，这同样也适用于其它的表达式。

## SomeThing can be improved
我们当前的实现是在 HistColl 的 Selectivity 方法中进行 expression 的计算，这就意味着我们只能实现对于能够下推到 DataSource 上的 expression 进行选择率的计算，然后该选择率算出来的行数会传递到 DataSource 的父亲节点，依次计算递归到 Root 节点，但对于物理优化阶段，还需要将整个获取统计信息的递归的过程都实现基于采样的行数估计。

当然，在实现了基本的功能之后（比如在当前默认的查询优化器下），需要测试再确定是否有必要继续深入或需要进行怎样的优化。因为采样的过程也会存在一定的开销，这其实和之前 Paper Reading 分享的 smooth scan 一样，是一个 **trade off** 的过程。因此首先需要确定其对内存的消耗换取算出一个更优的查询计划在执行时间上的收益是否可以接受，同时需要确定采样的过程对于集群负载的影响是否能够被其选一个更优的执行计划在集群中执行带来的收益所抵消，如对 QPS 指标的影响等。

如果用动态采样来估算行数在查询中能够带来一定收益，那么将其拓展到 Cascade optimizer 上将会获得更大的优化效果，因为新的优化器框架将会把规则转化和代价模型放到一起做，这就意味着将逻辑优化和物理优化结合在一起，显然这将扩大执行计划的搜索空间，那么更加精确的统计信息直觉上将能够获得更优的执行计划。

## 写在最后
比赛最后答辩阶段看到其它组实现的 Demo，真的是厉害到爆炸，印象最深的除了狂拽酷炫的 TiDB-Wasm 和大道至简的 Unified Thread Pool，就是十分钟前还在一起吐槽“打扰了”的杜川大佬，答辩时候那种行云流水的操作，我真的是打扰了。

Hackathon 和 Talent Plan 确实让我切身感受到了 PingCAP 的技术热情与团队文化，PingCAP University 确实如一个 University，不管结果怎样，整个与老师交流、动手实践及团队协作的过程能够学习到的东西确实是比在学校来得多。

最后感谢 SQL Engine 组的海滨、张健及珂男老师，每次引导式的提问总是能让我更加清晰的理解问题，更快的找到问题的答案与当前的不足。同时感谢琳琳姐在 Talent Plan 活动上的付出，感谢广州 Office 源源不断的零食水果供应及各位小伙伴在技术问题上的帮助。