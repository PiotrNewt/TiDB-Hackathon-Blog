# TiDB Hackathon Blog
回望 10 月，TiDB Hackathon 两天及 Talent Plan 在 PingCAP 广州 Office 度过的这几周真的使我印象深刻。
我是电子科技大学研二的一名学生，我和我的 partner 吕小荣本次是以 PingCAP Talent Plan 学员的身份参加 Hackathon，虽然没有得奖，但是对于第一次参加 Hackathon 比赛的我来说也是收获满满。Talent Plan 的题目是官方确定的，我们在其中选到的是「基于采样的行数估计」，本文主要阐述在这个题目下的一些设计与实现。

首先做这个项目的动机是由于 TiDB 当前的查询优化存在以下问题：
- 无法对一些特殊的表达式进行行数估计，如 `Select * From t Where abs(a) > 10;`
- 无法对列相关的查询进行精确的行数估算，如 `Select * From t Where a > 1 and b > 2;`
- 长时间没有 `Analyze Table` 将导致统计信息过期

比如在处理 `abs()` 时，优化器无法通过当前的统计信息计算出通过表达式之后的行数，因此会直接返回一个假的选择率：

```sql
mysql> Explain Select * From t Where abs(a) > 10;
+---------------------+----------+-----------+------------------------------------------------------------+
| id                  | count    | task      | operator info                                              |
+---------------------+----------+-----------+------------------------------------------------------------+
| TableReader_7       | 26214.40 | root      | data:Selection_6                                           |
| └─Selection_6       | 26214.40 | cop[tikv] | gt(abs(Column#1), 10)                                      |
|   └─TableScan_5     | 32768.00 | cop[tikv] | table:t, range:[-inf,+inf], keep order:false, stats:pseudo |
+---------------------+----------+-----------+------------------------------------------------------------+
3 rows in set (0.01 sec)
```

可以看到 `abs(a) > 10` 的选择率返回的是默认值 0.8，如果我们将统计信息 Drop 掉，那么结果更加明显：

```sql
mysql> Drop Stats t;
Query OK, 0 rows affected (0.07 sec)

mysql> Explain Select * From t Where abs(a) > 10;
+---------------------+----------+-----------+------------------------------------------------------------+
| id                  | count    | task      | operator info                                              |
+---------------------+----------+-----------+------------------------------------------------------------+
| TableReader_7       | 8000.00  | root      | data:Selection_6                                           |
| └─Selection_6       | 8000.00  | cop[tikv] | gt(abs(Column#1), 10)                                      |
|   └─TableScan_5     | 10000.00 | cop[tikv] | table:t, range:[-inf,+inf], keep order:false, stats:pseudo |
+---------------------+----------+-----------+------------------------------------------------------------+
3 rows in set (0.00 sec)
```

对于列相关的查询，由于在构建统计信息的时候假设两列独立，所以在处理列相关的查询的统计信息时，优化器只是简单的将两列的选择率相乘，无法精确估计行数：

```sql
mysql> Analyze table t;
Query OK, 0 rows affected (0.56 sec)

mysql> Explain Select * From t Where a > 1 and b > 2;
+---------------------+----------+-----------+----------------------------------------------+
| id                  | count    | task      | operator info                                |
+---------------------+----------+-----------+----------------------------------------------+
| TableReader_7       | 3640.89  | root      | data:Selection_6                             |
| └─Selection_6       | 3640.89  | cop[tikv] | gt(Column#1, 1), gt(Column#2, 2)             |
|   └─TableScan_5     | 32768.00 | cop[tikv] | table:t, range:[-inf,+inf], keep order:false |
+---------------------+----------+-----------+----------------------------------------------+
3 rows in set (0.00 sec)

mysql> Select count(*) From t Where a > 1 and b > 2;
+----------+
| count(*) |
+----------+
|    32670 |
+----------+
1 row in set (0.35 sec)
```

因此，为了解决无法使用统计信息对一些特殊表达式进行计算及列与列的统计信息相互独立的问题，我们可以通过使用表的**样本**在查询优化器中替代现有统计信息进行物理优化；同时为了解决统计信息可能因为过期而不准确的问题，可以使用**动态采样**的方法进行表的样本收集。

打个不太严谨（但易于理解）的比方：这个过程类似于先在优化器中做一次小的表的查询，以查询过程各个算子的结果来指导执行计划的生成，整个过程如下图：

<div align=center>
  <img src=./Img/Imp_process.png height=350>
</div>

## 设计与实现
为了实现基于采样的行数估计，我们需要解决最核心的三个问题：
- 在哪里实现？
- 如何实现对表的采样？
- 如何使用表的采样来估算行数？

### 在哪里实现
先不考虑现在正在完善的 Cascade 优化器，我们先回顾一下 TiDB 当前的默认优化器的实现，以确定应该在什么地方触发表的采样及采样的结果应该用在什么地方。
当前 TiDB 的优化器实现主要是 Volcano 模型，在 `planBuilder` 将 AST(Abstract Syntax Tree) 转化为逻辑计划树之后，按照优化阶段分为了**逻辑优化**与**物理优化**两个阶段，逻辑优化阶段使用规则进行逻辑计划树的变换，物理优化阶段主要是使用代价模型来选择物理算子。

传统的物理优化主要决定以下三点：
- **单表**：Access Path，即从物理表中取到数据的路径，通常是决定是否使用索引扫描，索引扫描后是否需要回表等；
- **两表**：Join Approach，即两表实际 Join 的实现方式，如 Hash Jion 和 Sort-Merge Join 的选择；
- **多表**：Join Order，即多个表 Join 的顺序，较优的连接顺序往往会产生较少的中间结果，从而减少不必要的计算；

当前的 TiDB 对 Join Order 的计算是放在逻辑优化阶段实现的，为了简化实现这里暂不考虑，于是聚焦在物理优化阶段使用统计信息选择物理算子这个地方。如决定对于一张表在 KV 上的访问应该是 TableScan，IndexScan 或是 IndexLookUpScan，这在 TiDB 中的实现是将 `DataSource` 这样的逻辑算子转化为 `TableReader`, `IndexReader` 或 `IndexLookUpReader`。

具体的，在进入物理优化的时候，优化器会对逻辑优化的结果中每一个逻辑算子（逻辑计划树的节点）自底向上递归的计算通过节点后的统计信息，然后根据代价模型，从逻辑计划树 Root 节点出发自顶向下的选择代价最小的物理算子。因此，触发采样和统计信息的使用可以实现在物理优化阶段获取统计信息的部分。

### 如何实现对表的采样
实现对表的采样需要考虑两个问题：
- 什么时候采集？即当查询到来的时候，应该在什么条件下触发样本的采集
- 怎么采集？即如何从 TiKV 快速的获取到一些表数据的随机样本

对于什么时候采集的问题，我们在 TiDB 中添加了一个系统变量来确定：
- 当前 TiDB 节点是否需要使用表样本来进行查询优化
- 当前的样本收集是否需要阻塞本次查询（由于可以将样本 cache 到内存中，短时间对于一个表的查询可以复用而不用再次采样）
- 表的采样率

这个系统变量有 `0-10` 共 11 个等级，他们与上述条件的对应关系如下：

| 不使用采样 | 采样但不阻塞查询 | 采样并阻塞本次查询 |
|:-:|:-:|:-:|
| 0 | 1-5 | 6-10 |

相比于将触发条件写死的策略来说，使用系统变量可以根据应用场景的不同灵活控制采样的行为，提高该功能对于不同场景的适应性。

对于怎么采集的问题，由于表数据都存储在 TiKV 上，因此要想实现采样这个功能，我们需要将这种在 TiDB 节点上实现的特殊方法推到 TiKV 上实现对应的操作。

好在 TiDB 在 Analyze Table 统计生成等深直方图和 CM-Sketch 也需要对表的数据进行一次采集，更棒的是，为了提高统计信息生成的效率，TiDB 实现了 FastAnalyze 这个功能，这个功能在 KV 上随机的取一些数据返回到 TiDB 上用于生成等深直方图和 CM-Sketch，在表的行数不大于采样行数的 2 倍时，其行为和普通的 Analyze 一样，如果大于 2 倍采样行数，那么会从表的每个 Region 随机抽取一些元组进行返回而不会 Scan 整个 Region，这样大大提高了效率。

于是我们复用了 FastAnalyze 的部分代码在 TiDB 上实现了采样的过程，具体如下图：

<div align=center>
  <img src=./Img/Sampling.png height=350>
</div>

不一样的是，为了方便后续 expression 的计算，我们在 HistColl 中采用 `Chunk` 的结构维护了样本信息。

### 如何使用表的采样来估算行数
从查询优化器的角度上来讲，行数估计实现在进入物理优化后的第一步。由于采样时候将样本封装到了 HistColl 中，因此优化器在物理优化阶段递归的计算逻辑计划树每个节点的统计信息时能够直接拿到样本，通过样本经过逻辑节点的计算逻辑即可计算出通过这个节点后包括行数的统计信息。

<div align=center>
  <img src=./Img/DeriveStats.png height=300>
</div>

由于采集的时候将样本维护成了 chunk，因此只用简单的调用表达式计算的接口，然后对计算结果进行统计就能获得选择率，通过选择率即可计算出行数，这同样也适用于其它的表达式。

## 一些可以改进的地方
我们当前的实现是在 HistColl 的 Selectivity 方法中进行表达式的计算，而只有能够下推到 DataSource 的表达式时才会调用这个方法，这就意味着我们只能实现对于能够下推到 DataSource 上的 expression 进行选择率的计算。但在物理优化阶段需要对逻辑计划树中每个节点构建统计信息，而不同的算子有自己的计算逻辑，因此对于每个算子都要重写 Stats Derivation 的过程，将整个获取统计信息的构建过程都实现基于采样的行数估计。

当然，在实现了基本的功能之后（比如在当前默认的查询优化器下），需要测试再确定是否有必要继续深入或需要进行怎样的优化。因为采样的过程也会存在一定的开销，这其实和之前 [Paper Reading](https://www.bilibili.com/video/av46925336) 分享的 [Smooth Scan](https://stratos.seas.harvard.edu/files/stratos/files/smooth_vldbj.pdf) 一样，是一个 **trade off** 的过程。因此首先需要确定其对内存的消耗换取算出一个更优的查询计划在执行时间上的收益是否可以接受，同时需要确定采样的过程对于集群负载的影响是否能够被其选一个更优的执行计划在集群中执行带来的收益所抵消，如对 QPS 指标的影响等。

如果用动态采样来估算行数在查询中能够带来一定收益，那么将其拓展到 Cascade Optimizer 上将会获得更大的优化效果，因为新的优化器框架将会把规则转化和代价模型放到一起做，这就意味着将逻辑优化和物理优化结合在一起，显然这将扩大执行计划的搜索空间，那么更加精确的统计信息将变得尤为重要。

## 写在最后
比赛最后答辩阶段看到其它组实现的 Demo，真的是厉害到爆炸，印象最深的除了狂拽酷炫的 TiDB-Wasm 和大道至简的 Unified Thread Pool，就是十分钟前还在一起吐槽“打扰了”的杜川大佬，答辩时候那种行云流水的操作，我真的是打扰了。

Hackathon 和 Talent Plan 确实让我切身感受到了 PingCAP 的技术热情与团队文化，PingCAP University 确实如一个 University，不管结果怎样，整个与老师交流、动手实践及团队协作的过程能够学习到的东西确实是比在学校来得多。

最后感谢 SQL Engine 组的海滨、张建及珂男老师，每次引导式的提问总是能让我更加清晰的理解问题，更快的找到问题的答案与当前的不足。同时感谢琳琳姐在 Talent Plan 活动上的付出，感谢广州 Office 源源不断的零食水果供应及各位小伙伴在技术问题上的帮助。
